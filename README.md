# 분리위키 모델 학습 및 데이터 파이프라인 구축

## 1. 프로젝트 개요

* **프로젝트명**: 분리위키 모델 학습 및 데이터 파이프라인 구축
* **프로젝트 기간**: 2024.03 ~ 2024.11
* **목적 및 배경**: 분리배출 가이드 제공 서비스인 "분리위키"를 AI 기능을 위해,

  * **혐오 표현 분류 (KcBERT)**
  * **이미지 기반 재활용 품목 분류 (YOLOv8)**
    모델 학습 자동화 및 배포 파이프라인을 구축하였습니다.
    주기적인 학습/저장/적재를 통해 **지속적으로 갱신 가능한 AI 모델 관리 시스템**을 설계하고 구현하였습니다.


## 2. 기술 스택

| 분류                 | 기술 목록                                                    |
| ------------------ | -------------------------------------------------------- |
| **개발 언어 및 환경**     | Python 3.10, Docker, Docker Compose                      |
| **AI 모델 및 학습 도구**  | KcBERT (Transformers), YOLOv8 (Ultralytics), TensorBoard |
| **데이터 처리 및 파이프라인** | Apache Airflow, Apache Spark, Pandas, SQLAlchemy         |
| **인프라 및 배포**       | AWS S3, AWS RDS (MySQL), PostgreSQL, boto3               |
| **로깅 및 모니터링**      | loguru, TensorBoard                                      |



## 3. 전체 파이프라인 구성 및 시스템 아키텍처

* **DAG 기반 자동화 흐름**

  * Apache Airflow를 활용하여 데이터 수집부터 학습, 저장까지 전 과정 자동화
  * Google Sheet 및 RDS 기반 데이터 수집 → Spark 전처리 → PostgreSQL 저장
  * KoBERT 모델 학습 (`midas_training_dag`) 및 YOLOv8 모델 학습 (`midas_yolo_dag`) 자동화

* **모델 버전 관리 및 서빙 연동**

  * 학습된 모델은 `.pt` 파일로 저장되어 S3에 업로드
  * `latest_model.yaml`을 통해 FastAPI 서버와 자동 연동되어 최신 모델 반영

* **DAG 구성 요약**

  | DAG 이름                  | 역할                                    |
  | ----------------------- | ------------------------------------- |
  | `midas_dag`             | Google Sheet 기반 정책 수집 및 PostgreSQL 반영 |
  | `midas_hate_speech_dag` | 댓글 수집 및 정제 → `midas_training_dag` 트리거 |
  | `midas_training_dag`    | KoBERT 학습 및 S3 저장 + YAML 업데이트         |
  | `midas_yolo_dag`        | YOLOv8 학습 및 모델 버전 관리 자동화 + YAML 업데이트          |

* **모델 성능 시각화**

  * 학습 로그는 TensorBoard 로그 경로에 자동 저장되며
  * PR Curve, F1 Score 등 성능 지표 시각화 가능



## 4. 문제 해결

* **모델 버전 관리 및 비용 이슈**   
  MLflow를 도입하려 하였으나, 구성 이해 부족 및 AWS 환경 설정 미숙으로 도입에 실패함. 이후 `.pt`, `params.yaml`, `latest_model.yaml`을 직접 저장하는 방식으로 대체함.   
  이 과정에서 **모델 용량 관리 미흡으로 AWS S3 과금 이슈가 발생**하였으며, AWS 지원팀에 문의하여 비용 면제를 받은 경험이 있음.

* **데이터 정제 및 클래스 통합 설계**   
  노트북 환경의 저장 공간 제약으로 인해 전체 데이터셋을 사용할 수 없었고, 학습에 적합한 BOX 타입 어노테이션만 선별하여 사용함.   
  또한, 분리배출 안내 서비스에서 실제로 분류해야 할 대상은 9종에 한정되어 있었기 때문에, 유사한 클래스를 통합하여 총 9개의 클래스로 재구성함.



## 5. 프로젝트 회고

* **모델 버전 및 실험 관리의 중요성 인식**   
  MLflow를 제대로 이해하지 못한 채 도입을 시도하면서 구조와 설정에 대한 부족한 이해로 인해 실패를 겪음.    
  이를 통해 버전 관리 및 실험 기록의 중요성을 실감하게 되었고, 다음 프로젝트에서는 MLflow를 충분히 학습한 후 체계적으로 재도입할 계획.

* **데이터 파이프라인의 디렉터리 구성 경험 부족**   
  설정 파일, DAG, Spark Job 등 다양한 파일들이 산발적으로 배치되어 있어 관리 및 협업에 비효율이 발생함.   
  이를 통해 Airflow 프로젝트 구조 전반에 대한 이해 부족을 느꼈으며,   
  특히 Spark와 Airflow를 함께 사용하는 경우 어떤 디렉터리 구조가 효과적인지 체계적으로 공부할 필요성을 절감함.

* **전이 학습 및 점진적 학습 설계의 필요성 인식**   
  기존 학습 모델을 기반으로 새로운 데이터를 반영하는 구조가 마련되어 있지 않았음.   
  추후에는 단순 재학습이 아닌 fine-tuning과 전이 학습도 가능하게 구현.

* **과도한 범위 설정으로 인한 파이프라인 미완성의 아쉬움**   
  새로운 기술 학습(Airflow, Spark 등)과 ML 모델 구현, ML 서빙 서버 구축, MLOps 파이프라인 구성 등 방대한 범위의 업무를 동시에 수행하다 보니,   
  일부 파이프라인은 계획대로 완성하지 못한 점이 아쉬움으로 남음.   
  이번 경험을 통해 자신의 역량과 학습 속도에 맞는 프로젝트 규모를 설정하는 것의 중요성을 깨달았고,   
  다음 프로젝트에서는 더 명확한 범위 설정과 우선순위 조정을 통해 완성도를 높이고자 함.
